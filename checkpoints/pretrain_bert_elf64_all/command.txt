{'FILENAME': 'pretrain.py',
 'arch': 'bert',
 'batch_size': 24,
 'dataroot': ['/var/tmp/sauravkadavath/binary/byteweight/elf_64/1/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/2/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/3/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/4/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/5/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/6/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/7/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/8/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/9/binary/*',
              '/var/tmp/sauravkadavath/binary/byteweight/elf_64/10/binary/*'],
 'epochs': 30,
 'grad_acc_steps': 1,
 'hidden_size': 16,
 'lr': 0.001,
 'mask_frac': 0.15,
 'master_addr': 'localhost',
 'master_port': '12345',
 'multistep_gamma': 0.2,
 'multistep_milestone': [2, 5, 10, 15, 20, 25],
 'num_attn_heads': 8,
 'num_layers': 2,
 'print_freq': 100,
 'savedir': 'checkpoints/pretrain_bert_elf64_all',
 'sequence_len': 1024,
 'world_size': 4}
